{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW9wX_syqHeP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.tensorboard as tensorboard\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "from math import sin, cos, sqrt, pi\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "#from tensorflow import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-ZeoQk09wQ4"
      },
      "outputs": [],
      "source": [
        "# Need to run this to load tensorboard in Colab\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1d3G6MJqWsX"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYjf1kcGqQJh"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, output_c):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.dimensions = [1024, 512, 256, 128]\n",
        "\n",
        "        # The paper specifices a kernel size of 5x5, however, that does not lead to an output image of 64x64\n",
        "        layers = [self._deconv_block(z_dim, self.dimensions[0], 4, 1, 0)]\n",
        "        for i in range(1, len(self.dimensions)):\n",
        "            layers.append( self._deconv_block(self.dimensions[i - 1], self.dimensions[i], 4,  2,  1) )\n",
        "        \n",
        "        layers += [nn.Sequential(nn.ConvTranspose2d(self.dimensions[-1], output_c, 4, 2, 1),\n",
        "                                 nn.Tanh())]\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def _deconv_block(self, in_c, out_c, k_size, stride, pad):\n",
        "        return nn.Sequential(nn.ConvTranspose2d(in_c, out_c, k_size, stride, pad, bias=False), # no need to add bias due to BatchNorm right afterwards\n",
        "                             nn.BatchNorm2d(out_c),\n",
        "                             nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_c):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.dimensions = [64, 128, 256, 512]\n",
        "\n",
        "        layers = [nn.Sequential(nn.Conv2d(input_c, self.dimensions[0], 4, 2, 1),\n",
        "                                nn.LeakyReLU(0.2))]\n",
        "\n",
        "        for i in range(1, len(self.dimensions)):\n",
        "            layers.append( self._conv_block(self.dimensions[i - 1], self.dimensions[i], 4,  2,  1) )\n",
        "        \n",
        "        layers += [nn.Conv2d(self.dimensions[-1], 1, 4, 2, 0)]  # No output activation. Discriminator outputs unbounded score\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def _conv_block(self, in_c, out_c, k_size, stride, pad):\n",
        "        return nn.Sequential(nn.Conv2d(in_c, out_c, k_size, stride, pad, bias=False),\n",
        "                             nn.BatchNorm2d(out_c),\n",
        "                             nn.LeakyReLU(0.2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x.reshape(-1, 1) # output size is N x 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvLouRv9-HB4"
      },
      "source": [
        "## Tensorboard Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaL7XgIT-DTA"
      },
      "outputs": [],
      "source": [
        "# run this cell before model training\n",
        "%tensorboard --logdir Tensorboard/WGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46z_J3NNqTlO"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d95UW6xnqnC"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # in-place operation\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "#model.apply(init_weights)\n",
        "\n",
        "def clip_weights(m, c=0.01):\n",
        "    if hasattr(m, 'weight'):\n",
        "        m.weight.data.clamp_(-c, c) # in-place operation\n",
        "    if hasattr(m, 'bias') and m.bias is not None:\n",
        "        m.bias.data.clamp_(-c, c) # in-place operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmSLQYzeqP_r"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "MODEL_DATA = \"Models/WGAN_model.pt\" # path to where model should be saved\n",
        "DATASET_ROOT = 'Datasets/img_align_celeba' # path to dataset\n",
        "\n",
        "lr = 5e-5\n",
        "z_dim = 100\n",
        "image_channels = 3\n",
        "image_size = 64\n",
        "n_critic = 5\n",
        "c = 0.01 # Discriminator weights clipping parameter\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "\n",
        "fixed_z = torch.rand((64, z_dim, 1, 1)).to(device) # for visualizing generator output throughout training\n",
        "\n",
        "# Set up tensorboard writers\n",
        "r_summary_writer = tensorboard.SummaryWriter('Tensorboard/WGAN/logs/real')\n",
        "f_summary_writer = tensorboard.SummaryWriter('Tensorboard/WGAN/logs/fake')\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(), #  normalizes image pixel values to [0, 1]\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "#train_dataset = datasets.MNIST(DATASET_ROOT, train=True, transform=preprocess, download=True)\n",
        "train_dataset = datasets.CelebA(DATASET_ROOT, preprocess)\n",
        "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "generator = Generator(z_dim, image_channels).to(device)\n",
        "discriminator = Discriminator(image_channels).to(device)\n",
        "\n",
        "# Initialize model weights from a normal distribution\n",
        "generator.apply(init_weights)\n",
        "discriminator.apply(init_weights)\n",
        "\n",
        "optim_g = torch.optim.RMSprop(generator.parameters(), lr=lr)\n",
        "optim_d = torch.optim.RMSprop(discriminator.parameters(), lr=lr)\n",
        "step = 0\n",
        "\n",
        "if os.path.isfile(MODEL_DATA):\n",
        "    checkpoint = torch.load(MODEL_DATA)\n",
        "    generator.load_state_dict(checkpoint['g_model_state_dict'])\n",
        "    discriminator.load_state_dict(checkpoint['d_model_state_dict'])\n",
        "\n",
        "    optim_g.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "    optim_d.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "    step = checkpoint['step']\n",
        "    d_loss = checkpoint['d_loss']\n",
        "    g_loss = checkpoint['g_loss']\n",
        "    print('Previous step:', step)\n",
        "    print('Previous generator loss', g_loss)\n",
        "    print('Previous discriminator loss', d_loss)\n",
        "\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    it = iter(enumerate(train))\n",
        "    out = next(it, None)\n",
        "    while out != None:\n",
        "        for _ in range(n_critic):\n",
        "            idx, real_samples = out\n",
        "            real_samples = real_samples.to(device)\n",
        "\n",
        "            z = torch.rand((BATCH_SIZE, z_dim, 1, 1)).to(device)\n",
        "            fake_samples = generator(z)\n",
        "            \n",
        "            scores_f = discriminator(fake_samples) # N x 1\n",
        "            scores_r = discriminator(real_samples) # N x 1\n",
        "\n",
        "            # Discriminator objective:\n",
        "            # Maximize the difference in critic scores for samples from the real distribution and generator's distribution\n",
        "            optim_d.zero_grad()\n",
        "            discriminator_loss = - (scores_r.mean() - scores_f.mean())\n",
        "            discriminator_loss.backward()#retain_graph=True) # need to retain graph in order to backpropogate through preds_f again later \n",
        "            \n",
        "            optim_d.step()\n",
        "\n",
        "            # discriminator weight clipping\n",
        "            discriminator.apply(clip_weights)\n",
        "            \n",
        "            out = next(it, None)\n",
        "            if out is None:\n",
        "                break\n",
        "\n",
        "        # Generator objective:\n",
        "        # Maximize critic scores of samples from the fake distribution\n",
        "        z = torch.rand((BATCH_SIZE, z_dim, 1, 1)).to(device)\n",
        "        fake_samples = generator(z)\n",
        "        optim_g.zero_grad()\n",
        "        scores_f = discriminator(fake_samples)\n",
        "        generator_loss = -scores_f.mean()\n",
        "        generator_loss.backward()\n",
        "\n",
        "        optim_g.step()\n",
        "\n",
        "        step += 1\n",
        "        # Print loss and save model\n",
        "        if (step - 1) % 3 == 0:\n",
        "            f_summary_writer.add_scalar('Generator loss', generator_loss.item(), global_step=step)\n",
        "            r_summary_writer.add_scalar('Discriminator  loss', discriminator_loss.item(), global_step=step)\n",
        "        \n",
        "        if (step - 1) % 100 == 0:\n",
        "            print('Epoch: %d/%d\\tBatch: %04d/%d' % (epoch, EPOCHS, idx, len(train)))\n",
        "            torch.save({'step': step,\n",
        "                        'g_model_state_dict': generator.state_dict(),\n",
        "                        'g_optimizer_state_dict': optim_g.state_dict(),\n",
        "                        'd_model_state_dict': discriminator.state_dict(),\n",
        "                        'd_optimizer_state_dict': optim_d.state_dict(),\n",
        "                        'g_loss': generator_loss.item(),\n",
        "                        'd_loss': discriminator_loss.item(),\n",
        "                        }, MODEL_DATA)\n",
        "        \n",
        "        if (step - 1) % 15 == 0:\n",
        "            with torch.no_grad():\n",
        "                fake_samples = generator(fixed_z)\n",
        "\n",
        "                img_grid_real = utils.make_grid(real_samples[:64], normalize=True, value_range=(-1,1))\n",
        "                img_grid_fake =  utils.make_grid(fake_samples, normalize=True, value_range=(-1,1))\n",
        "\n",
        "                r_summary_writer.add_image('Real', img_grid_real, global_step=step)\n",
        "                f_summary_writer.add_image('Fake', img_grid_fake, global_step=step)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WGAN_playground.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}